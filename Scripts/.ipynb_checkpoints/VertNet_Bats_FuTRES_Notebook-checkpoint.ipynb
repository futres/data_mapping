{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling Notebook for VertNet Bats Data\n",
    "<br />\n",
    "Neeka Sewnath\n",
    "<br />\n",
    "nsewnath@ufl.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import re\n",
    "import uuid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silencing warnings that are unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Vertnet Bats Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./../Original_Data/bats_2020-08-11b.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert coordinateuncertaintyinmeters to int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coordinateuncertaintyinmeters'] = df['coordinateuncertaintyinmeters'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up lifeStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in NA\n",
    "df[\"lifestage_cor\"] = df['lifestage_cor'].fillna(\"Not Collected\")\n",
    "\n",
    "# Create Filters\n",
    "adult = df['lifestage_cor']==\"Adult\"\n",
    "juvenile = df['lifestage_cor']==\"Juvenile\"\n",
    "ns = df['lifestage_cor']==\"NS\"\n",
    "\n",
    "# Assign correct terms using filters\n",
    "df['lifestage_cor'][adult] = \"adult\"\n",
    "df['lifestage_cor'][juvenile] = \"juvenile\"\n",
    "df['lifestage_cor'][ns] = \"Not Collected\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up country column TODO: Need to run with GEOME Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read GEOME country list\n",
    "geome_countries = pd.read_csv(\"./../Mapping Files/geome_country_list.csv\")\n",
    "\n",
    "# Create dictionary after inital GEOME run (create csv file first as a dictionary)\n",
    "df[\"country\"].unique()\n",
    "\n",
    "def country_correction(country): \n",
    "    \"\"\"Corrects country column to geome specific country list\"\"\"\n",
    "    if country in geome_countries.values:\n",
    "        return country\n",
    "    elif country in country_dictionary.keys():\n",
    "        return country_dictionary[country]\n",
    "    else:\n",
    "        country = \"Unknown\"\n",
    "        return country \n",
    "\n",
    "#df['country'] = df['country'].apply(country_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create yearCollected column TODO: Create varbatim filter after validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling N/As with \"Unknown\"\n",
    "df[\"eventdate\"] = df[\"eventdate\"].fillna(\"Unknown\")\n",
    "\n",
    "# Captures year within string\n",
    "def year_search(year):\n",
    "    \"\"\"Search string for 4 digit number and pass to correct function\"\"\"\n",
    "    if (re.search(r'\\d{4}$', year)):\n",
    "        return year_cleaner_front(year)\n",
    "    elif (re.search(r'^\\d{4}', year)):\n",
    "        return year_cleaner_back(year)\n",
    "\n",
    "def year_cleaner_front(year):\n",
    "    \"\"\"Isolate the year at the beginning of the string\"\"\"\n",
    "    cleaned_year = year[len(year)-4:len(year)]\n",
    "    return cleaned_year\n",
    "\n",
    "def year_cleaner_back(year):\n",
    "    \"\"\"Isolate the year at the end of the string\"\"\"\n",
    "    cleaned_year = year[0:4]\n",
    "    return cleaned_year\n",
    "\n",
    "df[\"yearCollected\"] = df[\"eventdate\"].apply(year_search)\n",
    "df[\"yearCollected\"] = df[\"yearCollected\"].fillna(\"Unknown\")\n",
    "\n",
    "df = df.assign(verbatimEventDate = df['verbatimeventdate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning reproductivecondition column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reproductivecondition\"].unique()\n",
    "\n",
    "# TODO: how to handle things like \"T=4.1 x 4.1 mm\"\n",
    "\n",
    "norep_filter = df[\"reproductivecondition\"].str.contains(\"\"\"non-reproductive|not lactating|no lact.\"\"\")\n",
    "preg_filter = df[\"reproductivecondition\"].str.contains(\"\"\"parous|1 emb|1 emb X 1 mm\"\"\")\n",
    "\n",
    "df[\"reproductivecondition\"][norep_filter == True] = \"non-reproductive\"\n",
    "df[\"reproductivecondition\"][preg_filter == True] = \"pregnant\"\n",
    "df[\"reproductivecondition\"][(preg_filter == False) & (norep_filter == False)] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean sex column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up sex column \n",
    "female = df['sex'] == \"female\"\n",
    "male = df['sex'] == \"male\"\n",
    "df['sex'][(female == False) & (male==False)] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding additional required GEOME columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(samplingProtocol = \"Unknown\")\n",
    "df = df.assign(basisOfRecord = \"PreservedSpecimen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correcting Country Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append countries to verbatim locality column\n",
    "df[\"locality\"] = df[\"locality\"] + \",\" + df[\"country\"]\n",
    "\n",
    "#Read GEOME country list\n",
    "geome_countries = pd.read_csv(\"./../Mapping Files/geome_country_list.csv\")\n",
    "\n",
    "country_dictionary = {\"U S A\":\"USA\", \"United States\":\"USA\",\n",
    "                      \"India, Nepal\":\"India\",\n",
    "                      \"Philippine Islands\":\"Philippines\",\n",
    "                      \"U.S. Virgin Islands\":\"Virgin Islands\",\n",
    "                      \"Republic of South Africa\":\"South Africa\",\n",
    "                      \"Commonwealth of the Northern Mariana Islands\":\"Northern Mariana Islands\",\n",
    "                      \"Federated States of Micronesia\":\"Micronesia\",\n",
    "                      \"ST VINCENT\":\"Saint Vincent and the Grenadines\",\n",
    "                      \"ENGLAND\":\"United Kingdom\",\n",
    "                      \"Trinidad & Tabago\":\"Trinidad and Tobago\",\n",
    "                      \"TRINIDAD & TOBAGO\":\"Trinidad and Tobago\",\n",
    "                      \"São Tomé & Principe\":\"Sao Tome and Principe\"}\n",
    "                      \n",
    "                      \n",
    "# \tUnapproved value(s):\n",
    "#\"ZOO\" in column \"country\" not in list \"country\"\n",
    "#\"Saint Barthélemy\" in column \"country\" not in list \"country\"\n",
    "#\"Trinidad\" in column \"country\" not in list \"country\"\n",
    "#\"Rhodesia\" in column \"country\" not in list \"country\"\n",
    "#\"Bonaire, Sint Eustatius and Saba\" in column \"country\" not in list \"country\"\n",
    "          \n",
    "def country_correction(country): \n",
    "    \"\"\"Corrects country column to geome specific country list\"\"\"\n",
    "    if country in geome_countries.values:\n",
    "        return country\n",
    "    elif country in country_dictionary.keys():\n",
    "        return country_dictionary[country]\n",
    "    else:\n",
    "        country = \"Unknown\"\n",
    "        return country \n",
    "\n",
    "df['country'] = df['country'].apply(country_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearrange columns so that template columns are first, followed by measurement values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column list\n",
    "cols = df.columns.tolist()\n",
    "\n",
    "# Specify desired columns\n",
    "cols = ['catalognumber',\n",
    "        'collectioncode',\n",
    "        'coordinateuncertaintyinmeters',\n",
    "        'dynamicproperties',\n",
    "        'decimallatitude',\n",
    "        'decimallongitude',\n",
    "        'verbatimlongitude',\n",
    "        'verbatimlatitude',\n",
    "        'institutioncode',\n",
    "        'verbatimEventDate',\n",
    "        'verbatimlocality',\n",
    "        'maximumelevationinmeters',\n",
    "        'minimumelevationinmeters',\n",
    "        'reproductivecondition',\n",
    "        'locality',\n",
    "        'fieldnotes',\n",
    "        'binomial',\n",
    "        'samplingProtocol',\n",
    "        'occurrenceid',\n",
    "        'occurrenceremarks',\n",
    "        'country',\n",
    "        'sex',\n",
    "        'lifestage_cor',\n",
    "        'basisOfRecord',\n",
    "        'yearCollected',\n",
    "        'body_mass.1.value',\n",
    "        'ear_length.1.value',\n",
    "        'hind_foot_length.1.value',\n",
    "        'tail_length.1.value',\n",
    "        'total_length.1.value',\n",
    "        'body_mass.1.units_inferred',\n",
    "        'ear_length.1.units_inferred',\n",
    "        'hind_foot_length.1.units_inferred',\n",
    "        'tail_length.1.units_inferred',\n",
    "        'total_length.1.units_inferred',\n",
    "        'body_mass.1.estimated_value',\n",
    "        'ear_length.1.estimated_value',\n",
    "        'hind_foot_length.1.estimated_value',\n",
    "        'tail_length.1.estimated_value',\n",
    "        'total_length.1.estimated_value']\n",
    "\n",
    "# Subset dataframe\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching template and column terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns \n",
    "df = df.rename(columns = {'catalognumber':'catalogNumber',\n",
    "                          'collectioncode': 'collectionCode',\n",
    "                          'institutioncode':'institutionCode',\n",
    "                          'coordinateuncertaintyinmeters':'coordinateUncertaintyInMeters',\n",
    "                          'fieldnotes':'eventRemarks',\n",
    "                          'decimallongitude': 'decimalLongitude',\n",
    "                          'decimallatitude':'decimalLatitude',\n",
    "                          'occurrenceid':'occurrenceID',\n",
    "                          'occurrenceremarks':'occurrenceRemarks',\n",
    "                          'binomial':'scientificName',\n",
    "                          'reproductivecondition':'reproductiveCondition',\n",
    "                          'maximumelevationinmeters':'maximumElevationInMeters',\n",
    "                          'dynamicproperties':'dynamicProperties',\n",
    "                          'minimumelevationinmeters':'minimumElevationInMeters',\n",
    "                          'verbatimlocality':'verbatimLocality',\n",
    "                          'verbatimlongitude':'verbatimLongitude',\n",
    "                          'verbatimlatitude':'verbatimLatitude',\n",
    "                          'lifestage_cor':'lifeStage'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add required GEOME column locality after reassigning locality to verbatimLocality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(locality=\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create individualID for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['individualID'] = np.arange(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a unique measurementMethod column for each desired trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of desired traits\n",
    "trait_name_list = [\"body_mass.1\",\"ear_length.1\",\"hind_foot_length.1\",\n",
    "                   \"tail_length.1\",\"total_length.1\"]\n",
    "\n",
    "method_list = [\"measurementMethod_\" + x for x in trait_name_list]\n",
    "df = df.join(pd.DataFrame(index = df.index, columns= method_list))\n",
    "\n",
    "def trait_method(trait):\n",
    "    \"\"\"\n",
    "    Adds measurementMethod information based off of \"True\" values in inferred value\n",
    "    and estimated value columns\n",
    "    \"\"\"\n",
    "    \n",
    "    column = \"measurementMethod_\" + trait\n",
    "    \n",
    "    inferred_column = trait + \".units_inferred\"\n",
    "    estimated_column = trait + \".estimated_value\"\n",
    "    \n",
    "    inferred_filter = df[inferred_column].astype(str).str.contains(\"TRUE|True|true\")\n",
    "    estimated_filter = df[estimated_column].astype(str).str.contains(\"TRUE|True|true\")\n",
    "    \n",
    "    df[column][inferred_filter] = \"Extracted with Traiter ; inferred value\"\n",
    "    df[column][estimated_filter] = \"Extracted with Traiter ; estimated value\"\n",
    "    df[column][estimated_filter & inferred_filter] = \"Extracted with Traiter ; estimated value; inferred value\"\n",
    "\n",
    "[trait_method(x) for x in trait_name_list]\n",
    "\n",
    "df = df.drop(columns = ['body_mass.1.units_inferred',\n",
    "                'ear_length.1.units_inferred',\n",
    "                'hind_foot_length.1.units_inferred',\n",
    "                'tail_length.1.units_inferred',\n",
    "                'total_length.1.units_inferred',\n",
    "                'body_mass.1.estimated_value',\n",
    "                'ear_length.1.estimated_value',\n",
    "                'hind_foot_length.1.estimated_value',\n",
    "                'tail_length.1.estimated_value',\n",
    "                'total_length.1.estimated_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating long version, first specifiying keep variables, then naming type and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_cols = ['catalogNumber', 'collectionCode', 'decimalLatitude','decimalLongitude',\n",
    "             'yearCollected','basisOfRecord','verbatimEventDate',\n",
    "            'institutionCode','lifeStage','verbatimLocality','locality', 'eventRemarks',\n",
    "            'samplingProtocol','country','sex','scientificName','dynamicProperties',\n",
    "            'maximumElevationInMeters', 'verbatimLongitude','individualID',\n",
    "            'minimumElevationInMeters','coordinateUncertaintyInMeters','verbatimLatitude',\n",
    "            'occurrenceID','occurrenceRemarks','reproductiveCondition']\n",
    "\n",
    "melt_cols = melt_cols + method_list\n",
    "\n",
    "melt_cols\n",
    "\n",
    "df_long = pd.melt(df,id_vars = melt_cols, var_name = 'measurementType', value_name = 'measurementValue')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull corresponding column value in measurement_method etc and append it to offical measurementMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_long.assign(measurementMethod = \"\")\n",
    "\n",
    "def method_add(trait,ind):\n",
    "    if trait == \"body_mass.1.value\":\n",
    "        return df_long[\"measurementMethod_body_mass.1\"][ind]\n",
    "    elif trait == \"ear_length.1.value\":\n",
    "        return df_long[\"measurementMethod_ear_length.1\"][ind]\n",
    "    elif trait == \"hind_foot_length.1.value\":\n",
    "        return df_long[\"measurementMethod_hind_foot_length.1\"][ind]\n",
    "    elif trait == \"tail_length.1.value\":\n",
    "        return df_long[\"measurementMethod_tail_length.1\"][ind]\n",
    "    elif trait == \"total_length.1.value\":\n",
    "        return df_long[\"measurementMethod_total_length.1\"][ind]\n",
    "\n",
    "df_long['ind'] = np.arange(len(df_long))\n",
    "\n",
    "df_long['measurementMethod'] = df_long.apply(lambda x: method_add(x.measurementType, x.ind), axis=1)\n",
    "\n",
    "df_long['measurementMethod'] = df_long['measurementMethod'].fillna(\"Extracted with Traiter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_long.drop(columns = method_list)\n",
    "df_long = df_long.drop(columns = 'ind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching trait and ontology terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trait dictionary \n",
    "trait_dict = {'body_mass.1.value':'body mass',\n",
    "              'ear_length.1.value': 'ear length to notch',\n",
    "              'hind_foot_length.1.value':'pes length',\n",
    "              'tail_length.1.value':'tail length',\n",
    "              'total_length.1.value':'body length'}\n",
    "\n",
    "def trait_rename(trait): \n",
    "    \"\"\"\n",
    "    Renames trait names with trait dictionary\n",
    "    \"\"\"\n",
    "    if trait in trait_dict.keys():\n",
    "        return trait_dict[trait]\n",
    "\n",
    "df_long['measurementType'] = df_long['measurementType'].apply(trait_rename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populating measurementUnit column with appropriate measurement units in long version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create measurementUnit column\n",
    "df_long = df_long.assign(measurementUnit=\"\")\n",
    "\n",
    "#Create filters\n",
    "long_body_mass_filter = df_long['measurementType']==\"body mass\"\n",
    "long_no_body_filter = df_long['measurementType']!=\"body mass\"\n",
    "\n",
    "#Assign units using filters\n",
    "df_long['measurementUnit'][long_body_mass_filter] = \"g\"\n",
    "df_long['measurementUnit'][long_no_body_filter] = \"mm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create diagnosticID which is a unique number for each measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_long.assign(diagnosticID = '')\n",
    "df_long['diagnosticID'] = np.arange(len(df_long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create materialSampleID which is a UUID for each measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_long.assign(materialSampleID = '')\n",
    "df_long['materialSampleID'] = [uuid.uuid4().hex for _ in range(len(df_long.index))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create eventID and populate it with materialSampleID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_long.assign(eventID = df_long[\"materialSampleID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make coordinateUncertaintyInMeters type integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If measurement value equals N/A, delete entire row. Drop range values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop N/A\n",
    "df_long = df_long.dropna(subset=['measurementValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211197"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking up the data into more managable sizes for validation and DE storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chunks list\n",
    "chunks = []\n",
    "\n",
    "# Separating files into chunks of ~50,000\n",
    "chunks = np.array_split(df_long, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating data chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped_data 0  done\n",
      "mapped_data 1  done\n",
      "mapped_data 2  done\n",
      "mapped_data 3  done\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(chunks)):\n",
    "    new=i+1\n",
    "    chunks[i].to_csv('../Mapped_Data/FuTRES_Bats_VertNet_Global_Modern_'+ str(new) +'.csv', index=False)\n",
    "    print(\"mapped_data\",i, \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
