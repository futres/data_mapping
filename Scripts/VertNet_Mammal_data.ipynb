{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Changes\n",
    "\n",
    "## template mapping files are in the git repository\n",
    "\n",
    "## original data in _CyVerse Discovery Environment_ \n",
    "### data file is: \"ODOVIRGCLEAN.csv\"\n",
    "\n",
    "### _lifeStage_ and _ageValue_\n",
    "- in _lifestage_\n",
    "- create new columns _ageValue_ and _ageUnit_\n",
    "- separate out lifeStage (e.g., juvenile, adult) from ageValue and ageUnit\n",
    "- make sure ageUnit is spelled out and singular (e.g., \"year\")\n",
    "\n",
    "### _yearCollected_\n",
    "- in _eventDate_\n",
    "- create new column _yearCollected_\n",
    "- separate out year\n",
    "- include century as well (e.g., 1999)\n",
    "\n",
    "### _unused columns_\n",
    "- LocationCode\n",
    "- Note\n",
    "\n",
    "## To Code\n",
    "### _measurementValue_\n",
    "- select only \"1st_\" measurement\n",
    "\n",
    "### _measurementUnit_\n",
    "- make sure either in \"g\" or \"mm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import re\n",
    "import uuid\n",
    "from dateutil.parser import parse\n",
    "from operator import eq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For large datasets\n",
    "- compress file\n",
    "- create script that checks if it is valid, if not reloads it, if _still_ not then waits a bit (exponential background)\n",
    "wget : bash command that dl files from websites (in terminal: brew install wget)\n",
    "get file && unzip\n",
    "\n",
    "*Note*: need hash (fingerprint) for file & stable link to version of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#wget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Mammal Vertnet Data Locally\n",
    "mammal = pd.read_csv(\"./mammals_no_bats_2019-03-13-2.csv\")\n",
    "\n",
    "# Import Mammal VertNet Data from Cyverse\n",
    "#mammal = pd.read_csv(\"./mammals_no_bats_2019-03-13.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prelimary data cleaning of yearCollected column\n",
    "\n",
    "# Filling N/As with \"Unknown\"\n",
    "mammal[\"eventdate\"]=mammal[\"eventdate\"].fillna(\"Unknown\")\n",
    "\n",
    "# Parsed through the eventdata column, identified year and moved year to new yearCollected column\n",
    "mammal=mammal.assign(yearCollected = '')\n",
    "\n",
    "# Creating event date variable\n",
    "verbatim_date=mammal['eventdate']\n",
    "\n",
    "# Establishing vertnet filter\n",
    "vertnet_date_filter = verbatim_date.str.contains(\"IV|0000|September|<|NW|latter|unknown|(MCZ)|(MSU)|present|and|;|&|mainly|between|Between|BETWEEN|OR|Unknown|UNKNOWN|#|TO|\\?|\\'|----|19--|No Date|\\,|\\d{4}-\\d{4}|(/n) /d|\\d{4}[s]| \\d{4}\\'[S]|1075-07-29|975-07-17| 2088| 9999| 0201\")\n",
    "\n",
    "# Grabbing clean data\n",
    "verbatim_date_clean= verbatim_date[vertnet_date_filter==False]\n",
    "index=list()\n",
    "\n",
    "# Parsing cleaned data for year, adding year to corresponding row in yearCollected\n",
    "for i in verbatim_date_clean.index:\n",
    "    string = verbatim_date_clean[i]\n",
    "    if (re.search(r'\\d{4}$', string)):\n",
    "        year = string[len(string)-4:len(string)]\n",
    "        mammal[\"yearCollected\"][i]=year\n",
    "    elif (re.search(r'^\\d{4}', string)):\n",
    "        year = string[0:4]\n",
    "        mammal[\"yearCollected\"][i]=year\n",
    "    else:\n",
    "        print(\"Not Added\") \n",
    "\n",
    "# Filling blank values with \"Unknown\"\n",
    "mammal.yearCollected.replace('', \"Unknown\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "mammal.to_csv('../Mapped Data/Mammal_CheckPoint.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal.to_csv('../Mapped Data/Mammal_CheckPoint.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from checkpoint (for troubleshooting to avoid rerunning yearCollected code)\n",
    "#mammal = pd.read_csv('../Mapped Data/Mammal_CheckPoint.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeka/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Clean up sex column \n",
    "female = mammal['sex']==\"female\"\n",
    "male = mammal['sex']==\"male\"\n",
    "mammal['sex'][(female == False)&(male==False)]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add required GEOME columns\n",
    "mammal=mammal.assign(samplingProtocol=\"Unknown\")\n",
    "mammal=mammal.assign(measurementMethod=\"Unknown\")\n",
    "mammal=mammal.assign(country=\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling basisOfRecord column\n",
    "\n",
    "#Loop to check if dynamic properties contain fossil mentions    \n",
    "#for ind in mammal.index:  \n",
    "#    a = mammal['dynamicproperties'][ind]\n",
    "#    b = str(a)\n",
    "#    if (b.find('fossilspecimen') != -1): \n",
    "#           print (\"Contains given substring \") \n",
    "#    else: \n",
    "#        pass  \n",
    "#print(\"finished\")\n",
    "        \n",
    "mammal=mammal.assign(basisOfRecord=\"PreservedSpecimen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create verbatimEventData column for columns that present a range\n",
    "mammal=mammal.assign(verbatimEventDate = '')\n",
    "mammal['verbatimEventDate']=mammal['eventdate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange columns so that template columns are first, followed by measurement values\n",
    "\n",
    "# Create column list\n",
    "cols = mammal.columns.tolist()\n",
    "\n",
    "# Specify desired columns\n",
    "cols = ['catalognumber',\n",
    "        'collectioncode',\n",
    "        'decimallatitude',\n",
    "        'decimallongitude',\n",
    "        'maximumelevationinmeters',\n",
    "        'minimumelevationinmeters',\n",
    "        'institutioncode',\n",
    "        'verbatimEventDate',\n",
    "        'locality',\n",
    "        'samplingProtocol',\n",
    "        'measurementMethod',\n",
    "        'country',\n",
    "        'sex',\n",
    "        'lifestage',\n",
    "        'scientificname',\n",
    "        'references',\n",
    "        'basisOfRecord',\n",
    "        'yearCollected',\n",
    "        '1st_body_mass',\n",
    "        #'1st_ear_length',\n",
    "        '1st_hind_foot_length',\n",
    "        '1st_tail_length',\n",
    "        '1st_total_length']\n",
    "# Subset dataframe\n",
    "mammal = mammal[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching template and column terms\n",
    "\n",
    "# Renaming columns \n",
    "mammal = mammal.rename(columns = {'catalognumber': 'catalogNumber',\n",
    "                                 'collectioncode':'collectionCode',\n",
    "                                 'decimallatitude':'decimalLatitude',\n",
    "                                 'decimallongitude':'decimalLongitude',\n",
    "                                 'maximumelevationinmeters':'maximumElevationInMeters',\n",
    "                                 'minimumelevationinmeters':'minimumElevationInMeters',\n",
    "                                 'institutioncode' :'institutionCode',\n",
    "                                 'locality':'verbatimLocality',\n",
    "                                 'lifestage':'lifeStage',\n",
    "                                 'scientificname':'scientificName'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching trait and ontology terms\n",
    "\n",
    "# Renaming columns\n",
    "mammal = mammal.rename(columns={'1st_body_mass':'body mass',\n",
    "                                #'1st_ear_length': 'ear length',\n",
    "                                '1st_hind_foot_length':'pes length',\n",
    "                                '1st_tail_length':'tail length',\n",
    "                                '1st_total_length':'body length'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create materialSampleID which is a UUID for each measurement\n",
    "mammal=mammal.assign(materialSampleID = '')\n",
    "mammal['materialSampleID'] = [uuid.uuid4().hex for _ in range(len(mammal.index))]\n",
    "\n",
    "# Create eventID and populate it with materialSampleID\n",
    "mammal=mammal.assign(eventID = mammal[\"materialSampleID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill unknown for scientificName\n",
    "mammal[\"scientificName\"]=mammal[\"scientificName\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add required GEOME column locality after reassigning locality to verbatimLocality\n",
    "mammal=mammal.assign(locality=\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create long version so that each trait has its own row\n",
    "\n",
    "# Creating long version, first specifiying keep variables, then naming variable and value\n",
    "\n",
    "longVersMammal=pd.melt(mammal,\n",
    "                      id_vars=['catalogNumber',\n",
    "                      'collectionCode',\n",
    "                      'decimalLatitude',\n",
    "                      'decimalLongitude',\n",
    "                      'maximumElevationInMeters', \n",
    "                      'minimumElevationInMeters',\n",
    "                      'yearCollected',\n",
    "                      'basisOfRecord',\n",
    "                      'verbatimEventDate',\n",
    "                      'institutionCode',\n",
    "                      'lifeStage',\n",
    "                      'verbatimLocality',\n",
    "                      'locality',\n",
    "                      'samplingProtocol',\n",
    "                      'measurementMethod',\n",
    "                      'country',\n",
    "                      'sex',\n",
    "                      'scientificName',\n",
    "                      'materialSampleID',\n",
    "                      'eventID',\n",
    "                      'references'], \n",
    "                var_name = 'measurementType',\n",
    "                value_name = 'measurementValue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeka/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/Users/neeka/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Populating measurementUnit column with appropriate measurement units in long version\n",
    "longVersMammal=longVersMammal.assign(measurementUnit=\"\")\n",
    "\n",
    "long_body_mass_filter=longVersMammal['measurementType']==\"body mass\"\n",
    "long_no_body_filter=longVersMammal['measurementType']!=\"body mass\"\n",
    "\n",
    "longVersMammal['measurementUnit'][long_body_mass_filter] = \"g\"\n",
    "longVersMammal['measurementUnit'][long_no_body_filter] = \"mm\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create diagnosticID which is a unique number for each measurement\n",
    "longVersMammal=longVersMammal.assign(diagnosticID = '')\n",
    "longVersMammal['diagnosticID'] = np.arange(len(longVersMammal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If measurement value equals N/A, delete entire row\n",
    "longVersMammal = longVersMammal.dropna(subset=['measurementValue'])\n",
    "\n",
    "# Drop first row of data, it contains no measurementValue but is still retained\n",
    "longVersMammal = longVersMammal.drop(longVersMammal.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing long data csv file\n",
    "longVersMammal.to_csv('../Mapped Data/Mammal_Data_Long.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476172\n"
     ]
    }
   ],
   "source": [
    "print(len(longVersMammal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neeka/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#Chunking the data in more managable sizes for GEOME\n",
    "\n",
    "# Create as many processes as there are CPUs on your machine\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "\n",
    "# Initiate the chunk size \n",
    "chunk_size = 50000\n",
    "\n",
    "# Create chunks\n",
    "chunks = [longVersMammal.ix[longVersMammal.index[i:i + chunk_size]] for i in range(0, longVersMammal.shape[0], chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped_data 0\n",
      "mapped_data 1\n",
      "mapped_data 2\n",
      "mapped_data 3\n",
      "mapped_data 4\n",
      "mapped_data 5\n",
      "mapped_data 6\n",
      "mapped_data 7\n",
      "mapped_data 8\n",
      "mapped_data 9\n"
     ]
    }
   ],
   "source": [
    "# Creating data chunks\n",
    "for i in range(len(chunks)):\n",
    "    new=i+1\n",
    "    chunks[i].to_csv('../Mapped Data/FuTRES_Mammals_VertNet_Global_Modern_'+ str(new) +'.csv', index=False)\n",
    "    print(\"mapped_data\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 -> needed to replace 2088 and 0201\n",
    "#2 -> needed to replace 1197\n",
    "#3 -> needed to replace 2088, 9999, 0201\n",
    "#4 -> needed to replace 0201, 9999\n",
    "#5 -> needed to replace 2088, 9999\n",
    "#6 -> needed to replace 0201\n",
    "#7 -> needed to replace 9999\n",
    "#8 -> needed to replace 9999, 0201, 2088\n",
    "#9 -> needed to replace 9999, 0201\n",
    "#10 -> needed to replace 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
