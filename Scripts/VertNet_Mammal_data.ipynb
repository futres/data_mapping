{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling Notebook for VertNet Mammal Data\n",
    "<br />\n",
    "Neeka Sewnath\n",
    "<br />\n",
    "nsewnath@ufl.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import re\n",
    "import uuid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silencing warnings that are unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Vertnet Mammal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal = pd.read_csv(\"./../Original_Data/no_bats_2020-08-12b.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean yearCollected column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filling N/As with \"Unknown\"\n",
    "mammal[\"eventdate\"] = mammal[\"eventdate\"].fillna(\"Unknown\")\n",
    "\n",
    "# Create yearCollected Column\n",
    "mammal = mammal.assign(yearCollected = '')\n",
    "\n",
    "# Creating event date variable\n",
    "verbatim_date = mammal['eventdate']\n",
    "\n",
    "# Establishing vertnet filter\n",
    "vertnet_date_filter = verbatim_date.str.contains(\"\"\"IV|0000|September|<|NW|latter|unknown|(MCZ)|(MSU)|present|\n",
    "                                                    and|;|&|mainly|between|Between|BETWEEN|OR|Unknown|UNKNOWN|\n",
    "                                                    #|TO|\\?|\\'|----|19--|No Date|\\,|\\d{4}-\\d{4}|(/n) /d|\\d{4}[s]|\n",
    "                                                    \\d{4}\\'[S]|1075-07-29|975-07-17|2088|9999|0201|1197|\n",
    "                                                    1260|4560|1024|1119|1192|1072|1186\"\"\")\n",
    "\n",
    "# Grabbing clean data\n",
    "verbatim_date_clean= verbatim_date[vertnet_date_filter==False]\n",
    "\n",
    "\n",
    "# Captures year within string\n",
    "def year_search(year):\n",
    "    \"\"\"Search string for 4 digit number and pass to correct function\"\"\"\n",
    "    if (re.search(r'\\d{4}$', year)):\n",
    "        return year_cleaner_front(year)\n",
    "    elif (re.search(r'^\\d{4}', year)):\n",
    "        return year_cleaner_back(year)\n",
    "\n",
    "def year_cleaner_front(year):\n",
    "    \"\"\"Isolate the year at the beginning of the string\"\"\"\n",
    "    cleaned_year = year[len(year)-4:len(year)]\n",
    "    return cleaned_year\n",
    "\n",
    "def year_cleaner_back(year):\n",
    "    \"\"\"Isolate the year at the end of the string\"\"\"\n",
    "    cleaned_year = year[0:4]\n",
    "    return cleaned_year\n",
    "\n",
    "mammal[\"yearCollected\"] = verbatim_date_clean.apply(year_search)\n",
    "mammal[\"yearCollected\"] = mammal[\"yearCollected\"].fillna(\"Unknown\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up lifeStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill in NA\n",
    "mammal[\"lifestage_cor\"] = mammal['lifestage_cor'].fillna(\"Not Collected\")\n",
    "\n",
    "# Create Filters\n",
    "adult = mammal['lifestage_cor']==\"Adult\"\n",
    "juvenile = mammal['lifestage_cor']==\"Juvenile\"\n",
    "ns = mammal['lifestage_cor']==\"NS\"\n",
    "\n",
    "# Assign correct terms using filters\n",
    "mammal['lifestage_cor'][adult] = \"adult\"\n",
    "mammal['lifestage_cor'][juvenile] = \"juvenile\"\n",
    "mammal['lifestage_cor'][ns] = \"Not Collected\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up sex column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up sex column \n",
    "female = mammal['sex']==\"female\"\n",
    "male = mammal['sex']==\"male\"\n",
    "mammal['sex'][(female == False)&(male==False)]=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill Scientific Names with unknown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal[\"binomial\"]=mammal[\"binomial\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding additional required GEOME columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal=mammal.assign(samplingProtocol=\"Unknown\")\n",
    "mammal=mammal.assign(measurementMethod=\"Unknown\")\n",
    "mammal=mammal.assign(basisOfRecord=\"PreservedSpecimen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create verbatimEventDate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal=mammal.assign(verbatimEventDate = '')\n",
    "mammal['verbatimEventDate']=mammal['eventdate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up country column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append countries to verbatim locality column\n",
    "mammal[\"locality\"] = mammal[\"locality\"] + \",\" + mammal[\"country\"]\n",
    "\n",
    "#Read GEOME country list\n",
    "geome_countries = pd.read_csv(\"./../Mapping Files/geome_country_list.csv\")\n",
    "\n",
    "country_dictionary = {\"United States\":\"USA\", \"U S A\":\"USA\", \n",
    "                      \"Philippine Islands\":\"Philippines\",\n",
    "                      \"Indonesia; Borneo\":\"Indonesia\",\n",
    "                      \"Malaysia; Malaya\":\"Malaysia\",\n",
    "                      \"U.S. Virgin Islands\":\"Virgin Islands\",\n",
    "                      \"Republic of South Africa\":\"South Africa\",\n",
    "                      \"Ivory Coast\":\"Cote d'Ivoire\",\n",
    "                      \"Federated States of Micronesia\":\"Micronesia\",\n",
    "                      \"Lesser Antilles; Grenada\":\"Grenada\",\n",
    "                      \"Indonesia; Java\":\"Indonesia\",\n",
    "                      \"Lesser Antilles; Saint Vincent\":\"Saint Vincent and the Grenadines\",\n",
    "                      \"Lesser Antilles; Barbados\":\"Barbados\",\n",
    "                      \"ST VINCENT\":\"Saint Vincent and the Grenadines\",\n",
    "                      \"Lesser Antilles; Montserrat\": \"Montserrat\",\n",
    "                      \"Indonesia; Sumatra\":\"Indonesia\",\n",
    "                      \"Virgin Islands, US\":\"Virgin Islands\",\n",
    "                      \"Lesser Antilles; Antigua\":\"Antigua and Barbuda\",\n",
    "                      \"England\":\"United Kingdom\",\n",
    "                      \"Republic of Trinidad and Tobago\":\"Trinidad and Tobago\",\n",
    "                      \"Trinidad And Tobago; Trinidad\":\"Trinidad and Tobago\",\n",
    "                      \"COMMONWEALTH OF THE NORTHERN MARIANA ISLANDS\":\"Northern Mariana Islands\",\n",
    "                      \"Congo\":\"Democratic Republic of the Congo\",\n",
    "                      \"Malaysia; Sabah\":\"Malaysia\",\n",
    "                      \"Lesser Antilles; Martinique\":\"Martinique\",\n",
    "                      \"Republic of the Marshall Islands\":\"Marshall Islands\",\n",
    "                      \"Commonwealth of the Bahamas\":\"Bahamas\",\n",
    "                      \"Trinidad & Tabago\":\"Trinidad and Tobago\",\n",
    "                      \"United Kingdom; England\":\"United Kingdom\",\n",
    "                      \"United Kingdom; Scotland\":\"United Kingdom\",\n",
    "                      \"United Kingdom; Wales\":\"United Kingdom\",\n",
    "                      \"Lesser Antilles; Dominica\":\"Dominica\",\n",
    "                      \"Papua, New Guinea\":\"Papua New Guinea\",\n",
    "                      \"People's Republic of China\":\"China\",\n",
    "                      \"SCOTLAND\":\"United Kingdom\"}\n",
    "\n",
    "def country_correction(country): \n",
    "    \"\"\"Corrects country column to geome specific country list\"\"\"\n",
    "    if country in geome_countries.values:\n",
    "        return country\n",
    "    elif country in country_dictionary.keys():\n",
    "        return country_dictionary[country]\n",
    "    else:\n",
    "        country = \"Unknown\"\n",
    "        return country \n",
    "\n",
    "mammal['country'] = mammal['country'].apply(country_correction)\n",
    "    \n",
    "#mammal['country'] = mammal.apply(lambda x: country_correction(x.country, x.ind), axis=1)\n",
    "#mammal['ind'] = np.arange(len(mammal))\n",
    "\n",
    "# Fill N/A with unknown\n",
    "#mammal[\"country\"]=mammal[\"country\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create verbatimElevation Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_max = mammal[\"maximumelevationinmeters\"].astype(str)\n",
    "string_min = mammal[\"minimumelevationinmeters\"].astype(str)\n",
    "mammal['verbatimElevation']= string_max + \",\" + string_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearrange columns so that template columns are first, followed by measurement values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column list\n",
    "cols = mammal.columns.tolist()\n",
    "\n",
    "# Specify desired columns\n",
    "cols = ['catalognumber',\n",
    "        'collectioncode',\n",
    "        'decimallatitude',\n",
    "        'decimallongitude',\n",
    "        'verbatimElevation',\n",
    "        'institutioncode',\n",
    "        'verbatimEventDate',\n",
    "        'locality',\n",
    "        'samplingProtocol',\n",
    "        'measurementMethod',\n",
    "        'country',\n",
    "        'sex',\n",
    "        'lifestage_cor',\n",
    "        'binomial',\n",
    "        'basisOfRecord',\n",
    "        'yearCollected',\n",
    "        'body_mass.1.value',\n",
    "        'ear_length.1.value',\n",
    "        'hind_foot_length.1.value',\n",
    "        'tail_length.1.value',\n",
    "        'total_length.1.value']\n",
    "\n",
    "# Subset dataframe\n",
    "mammal = mammal[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching template and column terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns \n",
    "mammal = mammal.rename(columns = {'catalognumber': 'catalogNumber',\n",
    "                                 'collectioncode':'collectionCode',\n",
    "                                 'decimallatitude':'decimalLatitude',\n",
    "                                 'decimallongitude':'decimalLongitude',\n",
    "                                 'maximumelevationinmeters':'maximumElevationInMeters',\n",
    "                                 'minimumelevationinmeters':'minimumElevationInMeters',\n",
    "                                 'institutioncode' :'institutionCode',\n",
    "                                 'locality':'verbatimLocality',\n",
    "                                 'lifestage_cor':'lifeStage',\n",
    "                                 'binomial':'scientificName'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching trait and ontology terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "mammal = mammal.rename(columns={'body_mass.1.value':'body mass',\n",
    "                                'ear_length.1.value': 'ear length to notch',\n",
    "                                'hind_foot_length.1.value':'pes length',\n",
    "                                'tail_length.1.value':'tail length',\n",
    "                                'total_length.1.value':'body length'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create materialSampleID which is a UUID for each measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal=mammal.assign(materialSampleID = '')\n",
    "mammal['materialSampleID'] = [uuid.uuid4().hex for _ in range(len(mammal.index))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create eventID and populate it with materialSampleID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal=mammal.assign(eventID = mammal[\"materialSampleID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add required GEOME column locality after reassigning locality to verbatimLocality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal=mammal.assign(locality=\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating long version, first specifiying keep variables, then naming type and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "longVersMammal=pd.melt(mammal,\n",
    "                      id_vars=['catalogNumber',\n",
    "                      'collectionCode',\n",
    "                      'decimalLatitude',\n",
    "                      'decimalLongitude',\n",
    "                      'verbatimElevation',\n",
    "                      'yearCollected',\n",
    "                      'basisOfRecord',\n",
    "                      'verbatimEventDate',\n",
    "                      'institutionCode',\n",
    "                      'lifeStage',\n",
    "                      'verbatimLocality',\n",
    "                      'locality',\n",
    "                      'samplingProtocol',\n",
    "                      'measurementMethod',\n",
    "                      'country',\n",
    "                      'sex',\n",
    "                      'scientificName',\n",
    "                      'materialSampleID',\n",
    "                      'eventID'], \n",
    "                var_name = 'measurementType',\n",
    "                value_name = 'measurementValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populating measurementUnit column with appropriate measurement units in long version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create measurementUnit column\n",
    "longVersMammal=longVersMammal.assign(measurementUnit=\"\")\n",
    "\n",
    "#Create filters\n",
    "long_body_mass_filter=longVersMammal['measurementType']==\"body mass\"\n",
    "long_no_body_filter=longVersMammal['measurementType']!=\"body mass\"\n",
    "\n",
    "#Assign units using filters\n",
    "longVersMammal['measurementUnit'][long_body_mass_filter] = \"g\"\n",
    "longVersMammal['measurementUnit'][long_no_body_filter] = \"mm\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create diagnosticID which is a unique number for each measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "longVersMammal=longVersMammal.assign(diagnosticID = '')\n",
    "longVersMammal['diagnosticID'] = np.arange(len(longVersMammal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If measurement value equals N/A, delete entire row. Drop range values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop N/A\n",
    "longVersMammal = longVersMammal.dropna(subset=['measurementValue'])\n",
    "\n",
    "#Drop Range Values\n",
    "range_value_filter=longVersMammal['measurementValue'].str.contains(\",|one\", na=False)\n",
    "longVersMammal['measurementValue'][range_value_filter] = float(\"nan\")\n",
    "longVersMammal = longVersMammal.dropna(subset=['measurementValue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking up the data into more managable sizes for validation and DE storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chunks list\n",
    "chunks = []\n",
    "\n",
    "# Separating files into chunks of ~500,000\n",
    "chunks = np.array_split(longVersMammal, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating data chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Mapped Data/FuTRES_Mammals_VertNet_Global_Modern_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-cce782013579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnew\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mchunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Mapped Data/FuTRES_Mammals_VertNet_Global_Modern_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mapped_data\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3384\u001b[0m         )\n\u001b[1;32m   3385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3386\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3387\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3388\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         )\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Mapped Data/FuTRES_Mammals_VertNet_Global_Modern_1.csv'"
     ]
    }
   ],
   "source": [
    "for i in range(len(chunks)):\n",
    "    new=i+1\n",
    "    chunks[i].to_csv('../Mapped Data/FuTRES_Mammals_VertNet_Global_Modern_'+ str(new) +'.csv', index=False)\n",
    "    print(\"mapped_data\",i, \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
