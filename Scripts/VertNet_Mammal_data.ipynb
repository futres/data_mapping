{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling Notebook for VertNet Mammal Data\n",
    "<br />\n",
    "Neeka Sewnath\n",
    "<br />\n",
    "nsewnath@ufl.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import re\n",
    "import uuid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silencing warnings that are unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Vertnet Mammal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal = pd.read_csv(\"./../Original_Data/no_bats_2020-08-12b.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean yearCollected column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filling N/As with \"Unknown\"\n",
    "mammal[\"eventdate\"] = mammal[\"eventdate\"].fillna(\"Unknown\")\n",
    "\n",
    "# Create yearCollected Column\n",
    "mammal = mammal.assign(yearCollected = '')\n",
    "\n",
    "# Creating event date variable\n",
    "verbatim_date = mammal['eventdate']\n",
    "\n",
    "# Establishing vertnet filter\n",
    "vertnet_date_filter = verbatim_date.str.contains(\"\"\"IV|0000|September|<|NW|latter|unknown|(MCZ)|(MSU)|present|\n",
    "                                                    and|;|&|mainly|between|Between|BETWEEN|OR|Unknown|UNKNOWN|\n",
    "                                                    #|TO|\\?|\\'|----|19--|No Date|\\,|\\d{4}-\\d{4}|(/n) /d|\\d{4}[s]|\n",
    "                                                    \\d{4}\\'[S]|1075-07-29|975-07-17|2088|9999|0201|1197|\n",
    "                                                    1260|4560|1024|1119|1192|1072|1186\"\"\")\n",
    "\n",
    "# Grabbing clean data\n",
    "verbatim_date_clean= verbatim_date[vertnet_date_filter==False]\n",
    "\n",
    "\n",
    "# Captures year within string\n",
    "def year_search(year):\n",
    "    \"\"\"Search string for 4 digit number and pass to correct function\"\"\"\n",
    "    if (re.search(r'\\d{4}$', year)):\n",
    "        return year_cleaner_front(year)\n",
    "    elif (re.search(r'^\\d{4}', year)):\n",
    "        return year_cleaner_back(year)\n",
    "\n",
    "def year_cleaner_front(year):\n",
    "    \"\"\"Isolate the year at the beginning of the string\"\"\"\n",
    "    cleaned_year = year[len(year)-4:len(year)]\n",
    "    return cleaned_year\n",
    "\n",
    "def year_cleaner_back(year):\n",
    "    \"\"\"Isolate the year at the end of the string\"\"\"\n",
    "    cleaned_year = year[0:4]\n",
    "    return cleaned_year\n",
    "\n",
    "mammal[\"yearCollected\"] = verbatim_date_clean.apply(year_search)\n",
    "mammal[\"yearCollected\"] = mammal[\"yearCollected\"].fillna(\"Unknown\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up lifeStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill in NA\n",
    "mammal[\"lifestage_cor\"] = mammal['lifestage_cor'].fillna(\"Not Collected\")\n",
    "\n",
    "# Create Filters\n",
    "adult = mammal['lifestage_cor']==\"Adult\"\n",
    "juvenile = mammal['lifestage_cor']==\"Juvenile\"\n",
    "ns = mammal['lifestage_cor']==\"NS\"\n",
    "\n",
    "# Assign correct terms using filters\n",
    "mammal['lifestage_cor'][adult] = \"adult\"\n",
    "mammal['lifestage_cor'][juvenile] = \"juvenile\"\n",
    "mammal['lifestage_cor'][ns] = \"Not Collected\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up sex column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up sex column \n",
    "female = mammal['sex']==\"female\"\n",
    "male = mammal['sex']==\"male\"\n",
    "mammal['sex'][(female == False)&(male==False)]=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill Scientific Names with unknown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal[\"binomial\"]=mammal[\"binomial\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding additional required GEOME columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal=mammal.assign(samplingProtocol=\"Unknown\")\n",
    "mammal=mammal.assign(basisOfRecord=\"PreservedSpecimen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create verbatimEventDate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal=mammal.assign(verbatimEventDate = '')\n",
    "mammal['verbatimEventDate']=mammal['eventdate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up country column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append countries to verbatim locality column\n",
    "mammal[\"locality\"] = mammal[\"locality\"] + \",\" + mammal[\"country\"]\n",
    "\n",
    "#Read GEOME country list\n",
    "geome_countries = pd.read_csv(\"./../Mapping Files/geome_country_list.csv\")\n",
    "\n",
    "country_dictionary = {\"United States\":\"USA\", \"U S A\":\"USA\", \n",
    "                      \"Philippine Islands\":\"Philippines\",\n",
    "                      \"Indonesia; Borneo\":\"Indonesia\",\n",
    "                      \"Malaysia; Malaya\":\"Malaysia\",\n",
    "                      \"U.S. Virgin Islands\":\"Virgin Islands\",\n",
    "                      \"Republic of South Africa\":\"South Africa\",\n",
    "                      \"Ivory Coast\":\"Cote d'Ivoire\",\n",
    "                      \"Federated States of Micronesia\":\"Micronesia\",\n",
    "                      \"Lesser Antilles; Grenada\":\"Grenada\",\n",
    "                      \"Indonesia; Java\":\"Indonesia\",\n",
    "                      \"Lesser Antilles; Saint Vincent\":\"Saint Vincent and the Grenadines\",\n",
    "                      \"Lesser Antilles; Barbados\":\"Barbados\",\n",
    "                      \"ST VINCENT\":\"Saint Vincent and the Grenadines\",\n",
    "                      \"Lesser Antilles; Montserrat\": \"Montserrat\",\n",
    "                      \"Indonesia; Sumatra\":\"Indonesia\",\n",
    "                      \"Virgin Islands, US\":\"Virgin Islands\",\n",
    "                      \"Lesser Antilles; Antigua\":\"Antigua and Barbuda\",\n",
    "                      \"England\":\"United Kingdom\",\n",
    "                      \"Republic of Trinidad and Tobago\":\"Trinidad and Tobago\",\n",
    "                      \"Trinidad And Tobago; Trinidad\":\"Trinidad and Tobago\",\n",
    "                      \"COMMONWEALTH OF THE NORTHERN MARIANA ISLANDS\":\"Northern Mariana Islands\",\n",
    "                      \"Congo\":\"Democratic Republic of the Congo\",\n",
    "                      \"Malaysia; Sabah\":\"Malaysia\",\n",
    "                      \"Lesser Antilles; Martinique\":\"Martinique\",\n",
    "                      \"Republic of the Marshall Islands\":\"Marshall Islands\",\n",
    "                      \"Commonwealth of the Bahamas\":\"Bahamas\",\n",
    "                      \"Trinidad & Tabago\":\"Trinidad and Tobago\",\n",
    "                      \"United Kingdom; England\":\"United Kingdom\",\n",
    "                      \"United Kingdom; Scotland\":\"United Kingdom\",\n",
    "                      \"United Kingdom; Wales\":\"United Kingdom\",\n",
    "                      \"Lesser Antilles; Dominica\":\"Dominica\",\n",
    "                      \"Papua, New Guinea\":\"Papua New Guinea\",\n",
    "                      \"People's Republic of China\":\"China\",\n",
    "                      \"SCOTLAND\":\"United Kingdom\"}\n",
    "\n",
    "def country_correction(country): \n",
    "    \"\"\"Corrects country column to geome specific country list\"\"\"\n",
    "    if country in geome_countries.values:\n",
    "        return country\n",
    "    elif country in country_dictionary.keys():\n",
    "        return country_dictionary[country]\n",
    "    else:\n",
    "        country = \"Unknown\"\n",
    "        return country \n",
    "\n",
    "mammal['country'] = mammal['country'].apply(country_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create verbatimElevation Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_max = mammal[\"maximumelevationinmeters\"].astype(str)\n",
    "string_min = mammal[\"minimumelevationinmeters\"].astype(str)\n",
    "mammal['verbatimElevation']= string_max + \",\" + string_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearrange columns so that template columns are first, followed by measurement values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column list\n",
    "cols = mammal.columns.tolist()\n",
    "\n",
    "# Specify desired columns\n",
    "cols = ['catalognumber',\n",
    "        'collectioncode',\n",
    "        'decimallatitude',\n",
    "        'decimallongitude',\n",
    "        'verbatimElevation',\n",
    "        'institutioncode',\n",
    "        'verbatimEventDate',\n",
    "        'occurenceremarks',\n",
    "        'occurenceid',\n",
    "        'verbatimlongitude',\n",
    "        'verbatimlatitude',\n",
    "        'locality',\n",
    "        'samplingProtocol',\n",
    "        'country',\n",
    "        'sex',\n",
    "        'lifestage_cor',\n",
    "        'binomial',\n",
    "        'basisOfRecord',\n",
    "        'yearCollected',\n",
    "        'body_mass.1.value',\n",
    "        'ear_length.1.value',\n",
    "        'hind_foot_length.1.value',\n",
    "        'tail_length.1.value',\n",
    "        'total_length.1.value', \n",
    "        'body_mass.1.units_inferred',\n",
    "        'ear_length.1.units_inferred',\n",
    "        'hind_foot_length.1.units_inferred',\n",
    "        'tail_length.1.units_inferred',\n",
    "        'total_length.1.units_inferred',\n",
    "        'body_mass.1.estimated_value',\n",
    "        'ear_length.1.estimated_value',\n",
    "        'hind_foot_length.1.estimated_value',\n",
    "        'tail_length.1.estimated_value',\n",
    "        'total_length.1.estimated_value']\n",
    "\n",
    "# Subset dataframe\n",
    "mammal = mammal[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching template and column terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns \n",
    "mammal = mammal.rename(columns = {'catalognumber': 'catalogNumber',\n",
    "                                 'collectioncode':'collectionCode',\n",
    "                                 'decimallatitude':'decimalLatitude',\n",
    "                                 'decimallongitude':'decimalLongitude',\n",
    "                                 'maximumelevationinmeters':'maximumElevationInMeters',\n",
    "                                 'minimumelevationinmeters':'minimumElevationInMeters',\n",
    "                                 'institutioncode' :'institutionCode',\n",
    "                                 'occurenceremarks':'occurenceRemarks',\n",
    "                                 'occurenceid':'occurenceID',\n",
    "                                 'verbatimlongitude':'verbatimLongitude',\n",
    "                                 'verbatimlatitude':'verbatimLatitude',\n",
    "                                 'locality':'verbatimLocality',\n",
    "                                 'lifestage_cor':'lifeStage',\n",
    "                                 'binomial':'scientificName'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create materialSampleID which is a UUID for each measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal=mammal.assign(materialSampleID = '')\n",
    "mammal['materialSampleID'] = [uuid.uuid4().hex for _ in range(len(mammal.index))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create eventID and populate it with materialSampleID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal=mammal.assign(eventID = mammal[\"materialSampleID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add required GEOME column locality after reassigning locality to verbatimLocality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal=mammal.assign(locality=\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a unique measurementMethod column for each desired trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of desired traits\n",
    "trait_name_list = [\"body_mass.1\",\"ear_length.1\",\"hind_foot_length.1\",\n",
    "                   \"tail_length.1\",\"total_length.1\"]\n",
    "\n",
    "method_list = [\"measurementMethod_\" + x for x in trait_name_list]\n",
    "mammal = mammal.join(pd.DataFrame(index = mammal.index, columns= method_list))\n",
    "\n",
    "def trait_method(trait):\n",
    "    \"\"\"\n",
    "    Adds measurementMethod information based off of \"True\" values in inferred value\n",
    "    and estimated value columns\n",
    "    \"\"\"\n",
    "    \n",
    "    column = \"measurementMethod_\" + trait\n",
    "    \n",
    "    inferred_column = trait + \".units_inferred\"\n",
    "    estimated_column = trait + \".estimated_value\"\n",
    "    \n",
    "    inferred_filter = mammal[inferred_column].astype(str).str.contains(\"TRUE|True|true\")\n",
    "    estimated_filter = mammal[estimated_column].astype(str).str.contains(\"TRUE|True|true\")\n",
    "    \n",
    "    mammal[column][inferred_filter] = \"Extracted with Traiter ; inferred value\"\n",
    "    mammal[column][estimated_filter] = \"Extracted with Traiter ; estimated value\"\n",
    "    mammal[column][estimated_filter & inferred_filter] = \"Extracted with Traiter ; estimated value; inferred value\"\n",
    "\n",
    "[trait_method(x) for x in trait_name_list]\n",
    "\n",
    "mammal = mammal.drop(columns = ['body_mass.1.units_inferred',\n",
    "                'ear_length.1.units_inferred',\n",
    "                'hind_foot_length.1.units_inferred',\n",
    "                'tail_length.1.units_inferred',\n",
    "                'total_length.1.units_inferred',\n",
    "                'body_mass.1.estimated_value',\n",
    "                'ear_length.1.estimated_value',\n",
    "                'hind_foot_length.1.estimated_value',\n",
    "                'tail_length.1.estimated_value',\n",
    "                'total_length.1.estimated_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating long version, first specifiying keep variables, then naming type and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_cols = ['catalogNumber', 'collectionCode', 'decimalLatitude','decimalLongitude',\n",
    "            'verbatimElevation','yearCollected','basisOfRecord','verbatimEventDate',\n",
    "            'institutionCode','lifeStage','verbatimLocality','locality',\n",
    "            'samplingProtocol','country','sex','scientificName',\n",
    "            'materialSampleID','eventID']\n",
    "\n",
    "melt_cols = melt_cols + method_list\n",
    "\n",
    "longVersMammal = pd.melt(mammal,id_vars = melt_cols, var_name = 'measurementType', value_name = 'measurementValue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Extracted with Traiter ; inferred value',\n",
       "       'Extracted with Traiter ; estimated value',\n",
       "       'Extracted with Traiter ; estimated value; inferred value'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longVersMammal[\"measurementMethod_body_mass.1\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull corresponding column value in measurement_method etc and append it to offical measurementMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "longVersMammal = longVersMammal.assign(measurementMethod = \"\")\n",
    "\n",
    "def method_add(trait,ind):\n",
    "    if trait == \"body_mass.1.value\":\n",
    "        return longVersMammal[\"measurementMethod_body_mass.1\"][ind]\n",
    "    elif trait == \"ear_length.1.value\":\n",
    "        return longVersMammal[\"measurementMethod_ear_length.1\"][ind]\n",
    "    elif trait == \"hind_foot_length.1.value\":\n",
    "        return longVersMammal[\"measurementMethod_hind_foot_length.1\"][ind]\n",
    "    elif trait == \"tail_length.1.value\":\n",
    "        return longVersMammal[\"measurementMethod_tail_length.1\"][ind]\n",
    "    elif trait == \"total_length.1.value\":\n",
    "        return longVersMammal[\"measurementMethod_total_length.1\"][ind]\n",
    "\n",
    "longVersMammal['ind'] = np.arange(len(longVersMammal))\n",
    "\n",
    "longVersMammal['measurementMethod'] = longVersMammal.apply(lambda x: method_add(x.measurementType, x.ind), axis=1)\n",
    "\n",
    "longVersMammal['measurementMethod'] = longVersMammal['measurementMethod'].fillna(\"Extracted with Traiter\")\n",
    "\n",
    "longVersMammal = longVersMammal.drop(columns = method_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching trait and ontology terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trait dictionary \n",
    "trait_dict = {'body_mass.1.value':'body mass',\n",
    "              'ear_length.1.value': 'ear length to notch',\n",
    "              'hind_foot_length.1.value':'pes length',\n",
    "              'tail_length.1.value':'tail length',\n",
    "              'total_length.1.value':'body length'}\n",
    "\n",
    "def trait_rename(trait): \n",
    "    \"\"\"\n",
    "    Renames trait names with trait dictionary\n",
    "    \"\"\"\n",
    "    if trait in trait_dict.keys():\n",
    "        return trait_dict[trait]\n",
    "\n",
    "longVersMammal['measurementType'] = longVersMammal['measurementType'].apply(trait_rename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populating measurementUnit column with appropriate measurement units in long version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create measurementUnit column\n",
    "longVersMammal=longVersMammal.assign(measurementUnit=\"\")\n",
    "\n",
    "#Create filters\n",
    "long_body_mass_filter=longVersMammal['measurementType']==\"body mass\"\n",
    "long_no_body_filter=longVersMammal['measurementType']!=\"body mass\"\n",
    "\n",
    "#Assign units using filters\n",
    "longVersMammal['measurementUnit'][long_body_mass_filter] = \"g\"\n",
    "longVersMammal['measurementUnit'][long_no_body_filter] = \"mm\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create diagnosticID which is a unique number for each measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "longVersMammal=longVersMammal.assign(diagnosticID = '')\n",
    "longVersMammal['diagnosticID'] = np.arange(len(longVersMammal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If measurement value equals N/A, delete entire row. Drop range values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop N/A\n",
    "longVersMammal = longVersMammal.dropna(subset=['measurementValue'])\n",
    "\n",
    "#Drop Range Values\n",
    "range_value_filter=longVersMammal['measurementValue'].str.contains(\",|one\", na=False)\n",
    "longVersMammal['measurementValue'][range_value_filter] = float(\"nan\")\n",
    "longVersMammal = longVersMammal.dropna(subset=['measurementValue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking up the data into more managable sizes for validation and DE storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chunks list\n",
    "chunks = []\n",
    "\n",
    "# Separating files into chunks of ~500,000\n",
    "chunks = np.array_split(longVersMammal, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating data chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped_data 0  done\n",
      "mapped_data 1  done\n",
      "mapped_data 2  done\n",
      "mapped_data 3  done\n",
      "mapped_data 4  done\n",
      "mapped_data 5  done\n",
      "mapped_data 6  done\n",
      "mapped_data 7  done\n",
      "mapped_data 8  done\n",
      "mapped_data 9  done\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(chunks)):\n",
    "    new=i+1\n",
    "    chunks[i].to_csv('../Mapped_Data/FuTRES_Mammals_VertNet_Global_Modern_'+ str(new) +'.csv', index=False)\n",
    "    print(\"mapped_data\",i, \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
