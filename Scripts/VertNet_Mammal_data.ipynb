{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling Notebook for VertNet Mammal Data\n",
    "<br />\n",
    "Neeka Sewnath\n",
    "<br />\n",
    "nsewnath@ufl.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import re\n",
    "import uuid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silencing warnings that are unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Vertnet Mammal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645609"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./../Original_Data/all_mammals_2021-11-09a/all_mammals_2021-11-09a.csv\")\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add individualID and populate with UUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(individualID = '')\n",
    "data['individualID'] = [uuid.uuid4().hex for _ in range(len(data.index))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean yearCollected column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filling N/As with \"Unknown\"\n",
    "data[\"eventdate\"] = data[\"eventdate\"].fillna(\"Unknown\")\n",
    "\n",
    "# Create yearCollected Column\n",
    "data = data.assign(yearCollected = '')\n",
    "\n",
    "# Creating event date variable\n",
    "verbatim_date = data['eventdate']\n",
    "\n",
    "# Establishing vertnet filter\n",
    "vertnet_date_filter = verbatim_date.str.contains(\"\"\"IV|0000|September|<|NW|latter|unknown|(MCZ)|(MSU)|present|\n",
    "                                                    and|;|&|mainly|between|Between|BETWEEN|OR|Unknown|UNKNOWN|\n",
    "                                                    #|TO|\\?|\\'|----|19--|No Date|\\,|\\d{4}-\\d{4}|(/n) /d|\\d{4}[s]|\n",
    "                                                    \\d{4}\\'[S]|1075-07-29|975-07-17|2088|9999|0201|1197|\n",
    "                                                    1260|4560|1024|1119|1192|1072|1186|2364\"\"\")\n",
    "\n",
    "# Grabbing clean data\n",
    "verbatim_date_clean= verbatim_date[vertnet_date_filter==False]\n",
    "\n",
    "\n",
    "# Captures year within string\n",
    "def year_search(year):\n",
    "    \"\"\"Search string for 4 digit number and pass to correct function\"\"\"\n",
    "    if (re.search(r'\\d{4}$', year)):\n",
    "        return year_cleaner_front(year)\n",
    "    elif (re.search(r'^\\d{4}', year)):\n",
    "        return year_cleaner_back(year)\n",
    "\n",
    "def year_cleaner_front(year):\n",
    "    \"\"\"Isolate the year at the beginning of the string\"\"\"\n",
    "    cleaned_year = year[len(year)-4:len(year)]\n",
    "    return cleaned_year\n",
    "\n",
    "def year_cleaner_back(year):\n",
    "    \"\"\"Isolate the year at the end of the string\"\"\"\n",
    "    cleaned_year = year[0:4]\n",
    "    return cleaned_year\n",
    "\n",
    "data[\"yearCollected\"] = verbatim_date_clean.apply(year_search)\n",
    "data[\"yearCollected\"] = data[\"yearCollected\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up lifeStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill in NA\n",
    "data[\"lifestage_cor\"] = data['lifestage_cor'].fillna(\"Not Collected\")\n",
    "\n",
    "# Create Filters\n",
    "adult = data['lifestage_cor'] == \"Adult\"\n",
    "juvenile = data['lifestage_cor'] == \"Juvenile\"\n",
    "ns = data['lifestage_cor'] == \"NS\"\n",
    "\n",
    "# Assign correct terms using filters\n",
    "data['lifestage_cor'][adult] = \"adult\"\n",
    "data['lifestage_cor'][juvenile] = \"juvenile\"\n",
    "data['lifestage_cor'][ns] = \"Not Collected\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up sex column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up sex column \n",
    "female = data['sex'] == \"female\"\n",
    "male = data['sex'] == \"male\"\n",
    "data['sex'][(female == False) & (male == False)] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill Scientific Names with unknown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"binomial\"] = data[\"binomial\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding additional required GEOME columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(samplingProtocol = \"Unknown\")\n",
    "data = data.assign(basisOfRecord = \"PreservedSpecimen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create verbatimEventDate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(verbatimEventDate = '')\n",
    "data['verbatimEventDate'] = data['verbatimeventdate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up country column [obsolete in new data version]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append countries to verbatim locality column\n",
    "data[\"verbatimLocality\"] = data[\"locality\"] + \",\" + data[\"country\"]\n",
    "\n",
    "# Read GEOME country list\n",
    "geome_countries = pd.read_csv(\"./../Mapping Files/geome_country_list.csv\")\n",
    "\n",
    "country_dictionary = {\"United States\":\"USA\", \"U S A\":\"USA\", \n",
    "                      \"Philippine Islands\":\"Philippines\",\n",
    "                      \"Indonesia; Borneo\":\"Indonesia\",\n",
    "                      \"Malaysia; Malaya\":\"Malaysia\",\n",
    "                      \"U.S. Virgin Islands\":\"Virgin Islands\",\n",
    "                      \"Republic of South Africa\":\"South Africa\",\n",
    "                      \"Ivory Coast\":\"Cote d'Ivoire\",\n",
    "                      \"Federated States of Micronesia\":\"Micronesia\",\n",
    "                      \"Lesser Antilles; Grenada\":\"Grenada\",\n",
    "                      \"Indonesia; Java\":\"Indonesia\",\n",
    "                      \"Lesser Antilles; Saint Vincent\":\"Saint Vincent and the Grenadines\",\n",
    "                      \"Lesser Antilles; Barbados\":\"Barbados\",\n",
    "                      \"ST VINCENT\":\"Saint Vincent and the Grenadines\",\n",
    "                      \"Lesser Antilles; Montserrat\": \"Montserrat\",\n",
    "                      \"Indonesia; Sumatra\":\"Indonesia\",\n",
    "                      \"Virgin Islands, US\":\"Virgin Islands\",\n",
    "                      \"Lesser Antilles; Antigua\":\"Antigua and Barbuda\",\n",
    "                      \"England\":\"United Kingdom\",\n",
    "                      \"Republic of Trinidad and Tobago\":\"Trinidad and Tobago\",\n",
    "                      \"Trinidad And Tobago; Trinidad\":\"Trinidad and Tobago\",\n",
    "                      \"COMMONWEALTH OF THE NORTHERN MARIANA ISLANDS\":\"Northern Mariana Islands\",\n",
    "                      \"Congo\":\"Democratic Republic of the Congo\",\n",
    "                      \"Malaysia; Sabah\":\"Malaysia\",\n",
    "                      \"Lesser Antilles; Martinique\":\"Martinique\",\n",
    "                      \"Republic of the Marshall Islands\":\"Marshall Islands\",\n",
    "                      \"Commonwealth of the Bahamas\":\"Bahamas\",\n",
    "                      \"Trinidad & Tabago\":\"Trinidad and Tobago\",\n",
    "                      \"United Kingdom; England\":\"United Kingdom\",\n",
    "                      \"United Kingdom; Scotland\":\"United Kingdom\",\n",
    "                      \"United Kingdom; Wales\":\"United Kingdom\",\n",
    "                      \"Lesser Antilles; Dominica\":\"Dominica\",\n",
    "                      \"Papua, New Guinea\":\"Papua New Guinea\",\n",
    "                      \"People's Republic of China\":\"China\",\n",
    "                      \"SCOTLAND\":\"United Kingdom\"}\n",
    "\n",
    "def country_correction(country): \n",
    "    \"\"\"Corrects country column to geome specific country list\"\"\"\n",
    "    if country in geome_countries.values:\n",
    "        return country\n",
    "    elif country in country_dictionary.keys():\n",
    "        return country_dictionary[country]\n",
    "    else:\n",
    "        country = \"Unknown\"\n",
    "        return country \n",
    "\n",
    "data['country'] = data['country'].apply(country_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create verbatimElevation Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_max = data[\"maximumelevationinmeters\"].astype(str)\n",
    "string_min = data[\"minimumelevationinmeters\"].astype(str)\n",
    "data['verbatimElevation'] = string_max + \",\" + string_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearrange columns so that template columns are first, followed by measurement values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column list\n",
    "cols = data.columns.tolist()\n",
    "\n",
    "# Specify desired columns\n",
    "cols = ['catalognumber',\n",
    "        'collectioncode',\n",
    "        'decimallatitude',\n",
    "        'individualID',\n",
    "        'decimallongitude',\n",
    "        'verbatimElevation',\n",
    "        'maximumelevationinmeters',\n",
    "        'minimumelevationinmeters',\n",
    "        'institutioncode',\n",
    "        'verbatimEventDate',\n",
    "        'occurrenceremarks',\n",
    "        'occurrenceid',\n",
    "        'verbatimlongitude',\n",
    "        'verbatimlatitude',\n",
    "        'verbatimLocality',\n",
    "        'samplingProtocol',\n",
    "        'sex',\n",
    "        'country',\n",
    "        'lifestage_cor',\n",
    "        'binomial',\n",
    "        'basisOfRecord',\n",
    "        'yearCollected',\n",
    "        'body_mass.value',\n",
    "        'body_mass.units',\n",
    "        'ear_length.value',\n",
    "        'ear_length.units',\n",
    "        'hind_foot_length.value',\n",
    "        'hind_foot_length.units',\n",
    "        'tail_length.value',\n",
    "        'tail_length.units',\n",
    "        'total_length.value', \n",
    "        'total_length.units',\n",
    "        'body_mass.units_inferred',\n",
    "        'ear_length.units_inferred',\n",
    "        'hind_foot_length.units_inferred',\n",
    "        'tail_length.units_inferred',\n",
    "        'total_length.units_inferred',\n",
    "        'body_mass.estimated_value',\n",
    "        'ear_length.estimated_value',\n",
    "        'hind_foot_length.estimated_value',\n",
    "        'tail_length.estimated_value',\n",
    "        'total_length.estimated_value']\n",
    "\n",
    "# Subset dataframe\n",
    "data = data[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching template and column terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns \n",
    "data = data.rename(columns = {'catalognumber': 'catalogNumber',\n",
    "                              'collectioncode':'collectionCode',\n",
    "                              'decimallatitude':'decimalLatitude',\n",
    "                              'decimallongitude':'decimalLongitude',\n",
    "                              'institutioncode' :'institutionCode',\n",
    "                              'occurrenceremarks':'occurrenceRemarks',\n",
    "                              'maximumelevationinmeters':'maximumElevationInMeters',\n",
    "                              'minimumelevationinmeters':'minimumElevationInMeters',\n",
    "                              'occurrenceid':'occurrenceID',\n",
    "                              'verbatimlongitude':'verbatimLongitude',\n",
    "                              'verbatimlatitude':'verbatimLatitude',\n",
    "                              'lifestage_cor':'lifeStage',\n",
    "                              'binomial':'scientificName'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create materialSampleID which is a UUID for each measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(materialSampleID = '')\n",
    "data['materialSampleID'] = [uuid.uuid4().hex for _ in range(len(data.index))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create eventID and populate it with materialSampleID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(eventID = data[\"materialSampleID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add required GEOME column locality after reassigning locality to verbatimLocality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(locality=\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a unique measurementMethod column for each desired trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of desired traits\n",
    "trait_name_list = [\"body_mass\",\"ear_length\",\"hind_foot_length\",\n",
    "                   \"tail_length\",\"total_length\"]\n",
    "\n",
    "method_list = [\"measurementMethod_\" + x for x in trait_name_list]\n",
    "data = data.join(pd.DataFrame(index = data.index, columns= method_list))\n",
    "\n",
    "def trait_method(trait):\n",
    "    \"\"\"\n",
    "    Adds measurementMethod information based off of \"True\" values in inferred value\n",
    "    and estimated value columns\n",
    "    \"\"\"\n",
    "    \n",
    "    column = \"measurementMethod_\" + trait\n",
    "    \n",
    "    inferred_column = trait + \".units_inferred\"\n",
    "    estimated_column = trait + \".estimated_value\"\n",
    "    \n",
    "    inferred_filter = data[inferred_column].astype(str).str.contains(\"TRUE|True|true\")\n",
    "    estimated_filter = data[estimated_column].astype(str).str.contains(\"TRUE|True|true\")\n",
    "    \n",
    "    data[column][inferred_filter] = \"Extracted with Traiter ; inferred value\"\n",
    "    data[column][estimated_filter] = \"Extracted with Traiter ; estimated value\"\n",
    "    data[column][estimated_filter & inferred_filter] = \"Extracted with Traiter ; estimated value; inferred value\"\n",
    "\n",
    "[trait_method(x) for x in trait_name_list]\n",
    "\n",
    "data = data.drop(columns = ['body_mass.units_inferred',\n",
    "                'ear_length.units_inferred',\n",
    "                'hind_foot_length.units_inferred',\n",
    "                'tail_length.units_inferred',\n",
    "                'total_length.units_inferred',\n",
    "                'body_mass.estimated_value',\n",
    "                'ear_length.estimated_value',\n",
    "                'hind_foot_length.estimated_value',\n",
    "                'tail_length.estimated_value',\n",
    "                'total_length.estimated_value'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add filler to units column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"body_mass.units\"]= data[\"body_mass.units\"].fillna(\"unknown\")\n",
    "data[\"ear_length.units\"] = data[\"ear_length.units\"].fillna(\"unknown\")\n",
    "data[\"hind_foot_length.units\"] = data[\"hind_foot_length.units\"].fillna(\"unknown\")\n",
    "data[\"tail_length.units\"] = data[\"tail_length.units\"].fillna(\"unknown\")\n",
    "data[\"total_length.units\"] = data[\"total_length.units\"].fillna(\"unknown\")\n",
    "\n",
    "data[\"body_mass.value\"] = data[\"body_mass.value\"].fillna(\"unknown\")\n",
    "data[\"ear_length.value\"] = data[\"ear_length.value\"].fillna(\"unknown\")\n",
    "data[\"hind_foot_length.value\"] = data[\"hind_foot_length.value\"].fillna(\"unknown\")\n",
    "data[\"tail_length.value\"] =  data[\"tail_length.value\"].fillna(\"unknown\")\n",
    "data[\"total_length.value\"] = data[\"total_length.value\"].fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"body_mass_temp\"] = data[\"body_mass.value\"].astype(str) +\" ; \"+ data[\"body_mass.units\"]\n",
    "data[\"ear_length_temp\"] = data[\"ear_length.value\"].astype(str) + \" ; \"+data[\"ear_length.units\"]\n",
    "data[\"hind_foot_length_temp\"] = data[\"hind_foot_length.value\"].astype(str) + \" ; \" + data[\"hind_foot_length.units\"]\n",
    "data[\"tail_length_temp\"] = data[\"tail_length.value\"].astype(str) + \" ; \" + data[\"tail_length.units\"]\n",
    "data[\"total_length_temp\"] = data[\"total_length.value\"].astype(str) + \" ; \" + data[\"total_length.units\"]\n",
    "\n",
    "data = data.drop(columns = ['body_mass.value',\n",
    "                'ear_length.value',\n",
    "                'hind_foot_length.value',\n",
    "                'tail_length.value',\n",
    "                'total_length.value',\n",
    "                'body_mass.units',\n",
    "                'ear_length.units',\n",
    "                'hind_foot_length.units',\n",
    "                'tail_length.units',\n",
    "                'total_length.units'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating long version, first specifiying keep variables, then naming type and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_cols = ['catalogNumber', 'collectionCode', 'decimalLatitude','decimalLongitude',\n",
    "            'verbatimElevation','yearCollected','basisOfRecord','verbatimEventDate',\n",
    "            'institutionCode','lifeStage','verbatimLocality','locality', 'individualID',\n",
    "            'samplingProtocol','sex','scientificName', 'occurrenceRemarks','country',\n",
    "            'occurrenceID', 'verbatimLongitude', 'verbatimLatitude','materialSampleID','eventID',\n",
    "            'maximumElevationInMeters', 'minimumElevationInMeters',]\n",
    "\n",
    "melt_cols = melt_cols + method_list\n",
    "\n",
    "longVers  = pd.melt(data,id_vars = melt_cols, var_name = 'measurementType', value_name = 'measurementValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull corresponding column value in measurement_method etc and append it to offical measurementMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "longVers = longVers.assign(measurementMethod = \"\")\n",
    "\n",
    "def method_add(trait,ind):\n",
    "    if trait == \"body_mass_temp\":\n",
    "        return longVers[\"measurementMethod_body_mass\"][ind]\n",
    "    elif trait == \"ear_length_temp\":\n",
    "        return longVers[\"measurementMethod_ear_length\"][ind]\n",
    "    elif trait == \"hind_foot_length_temp\":\n",
    "        return longVers[\"measurementMethod_hind_foot_length\"][ind]\n",
    "    elif trait == \"tail_length_temp\":\n",
    "        return longVers[\"measurementMethod_tail_length\"][ind]\n",
    "    elif trait == \"total_length_temp\":\n",
    "        return longVers[\"measurementMethod_total_length\"][ind]\n",
    "\n",
    "longVers['ind'] = np.arange(len(longVers))\n",
    "\n",
    "longVers['measurementMethod'] = longVers.apply(lambda x: method_add(x.measurementType, x.ind), axis=1)\n",
    "\n",
    "longVers['measurementMethod'] = longVers['measurementMethod'].fillna(\"Extracted with Traiter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "longVers = longVers.drop(columns = method_list)\n",
    "longVers= longVers.drop(columns = 'ind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching trait and ontology terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trait dictionary \n",
    "trait_dict = {'body_mass_temp':'body mass',\n",
    "              'ear_length_temp': 'ear length to notch',\n",
    "              'hind_foot_length_temp':'pes length',\n",
    "              'tail_length_temp':'tail length',\n",
    "              'total_length_temp':'body length'}\n",
    "\n",
    "def trait_rename(trait): \n",
    "    \"\"\"\n",
    "    Renames trait names with trait dictionary\n",
    "    \"\"\"\n",
    "    if trait in trait_dict.keys():\n",
    "        return trait_dict[trait]\n",
    "\n",
    "longVers['measurementType'] = longVers['measurementType'].apply(trait_rename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating verbatimMeasurementUnit column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "longVers = longVers.assign(verbatimMeasurementUnit = \"\")\n",
    "longVers[['measurementValue', 'verbatimMeasurementUnit']] = longVers['measurementValue'].str.split(';', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populating measurementUnit column with appropriate measurement units in long version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create measurementUnit column\n",
    "longVers=longVers.assign(measurementUnit=\"\")\n",
    "\n",
    "#Create filters\n",
    "long_body_mass_filter=longVers['measurementType']==\"body mass\"\n",
    "long_no_body_filter=longVers['measurementType']!=\"body mass\"\n",
    "\n",
    "#Assign units using filters\n",
    "longVers['measurementUnit'][long_body_mass_filter] = \"g\"\n",
    "longVers['measurementUnit'][long_no_body_filter] = \"mm\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create diagnosticID which is a unique number for each measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "longVers=longVers.assign(diagnosticID = '')\n",
    "longVers['diagnosticID'] = np.arange(len(longVers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "longVers.to_csv('Peromyscus_maniculatus_VertNet_subset_pre_NA_drop.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If measurement value equals N/A, delete entire row. Drop range values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop N/A\n",
    "longVers[\"verbatimMeasurementUnit\"] = longVers[\"verbatimMeasurementUnit\"].replace({\"unknown\":\"\"})\n",
    "\n",
    "#Drop Range Values and unknowns\n",
    "range_value_filter=longVers['measurementValue'].str.contains(\",|one|unknown\", na=False)\n",
    "longVers['measurementValue'][range_value_filter] = float(\"nan\")\n",
    "longVers = longVers.dropna(subset=['measurementValue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking up the data into more managable sizes for validation and DE storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chunks list\n",
    "chunks = []\n",
    "\n",
    "# Separating files into chunks\n",
    "chunks = np.array_split(longVers, 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating data chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped_data 0  done\n",
      "mapped_data 1  done\n",
      "mapped_data 2  done\n",
      "mapped_data 3  done\n",
      "mapped_data 4  done\n",
      "mapped_data 5  done\n",
      "mapped_data 6  done\n",
      "mapped_data 7  done\n",
      "mapped_data 8  done\n",
      "mapped_data 9  done\n",
      "mapped_data 10  done\n",
      "mapped_data 11  done\n",
      "mapped_data 12  done\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(chunks)):\n",
    "    new=i+1\n",
    "    chunks[i].to_csv('../Mapped_Data/FuTRES_Mammals_VertNet_Global_Modern_'+ str(new) +'.csv', index=False)\n",
    "    print(\"mapped_data\",i, \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
