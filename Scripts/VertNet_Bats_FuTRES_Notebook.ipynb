{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling Notebook for VertNet Bats Data\n",
    "<br />\n",
    "Neeka Sewnath\n",
    "<br />\n",
    "nsewnath@ufl.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import re\n",
    "import uuid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silencing warnings that are unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Vertnet Bats Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./../Original_Data/bats_2020-08-11b.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up lifeStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in NA\n",
    "df[\"lifestage_cor\"] = df['lifestage_cor'].fillna(\"Not Collected\")\n",
    "\n",
    "# Create Filters\n",
    "adult = df['lifestage_cor']==\"Adult\"\n",
    "juvenile = df['lifestage_cor']==\"Juvenile\"\n",
    "ns = df['lifestage_cor']==\"NS\"\n",
    "\n",
    "# Assign correct terms using filters\n",
    "df['lifestage_cor'][adult] = \"adult\"\n",
    "df['lifestage_cor'][juvenile] = \"juvenile\"\n",
    "df['lifestage_cor'][ns] = \"Not Collected\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up country column TODO: Need to run with GEOME Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read GEOME country list\n",
    "geome_countries = pd.read_csv(\"./../Mapping Files/geome_country_list.csv\")\n",
    "\n",
    "# Create dictionary after inital GEOME run (create csv file first as a dictionary)\n",
    "df[\"country\"].unique()\n",
    "\n",
    "def country_correction(country): \n",
    "    \"\"\"Corrects country column to geome specific country list\"\"\"\n",
    "    if country in geome_countries.values:\n",
    "        return country\n",
    "    elif country in country_dictionary.keys():\n",
    "        return country_dictionary[country]\n",
    "    else:\n",
    "        country = \"Unknown\"\n",
    "        return country \n",
    "\n",
    "#df['country'] = df['country'].apply(country_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create yearCollected column TODO: Create varbatim filter after validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling N/As with \"Unknown\"\n",
    "df[\"eventdate\"] = df[\"eventdate\"].fillna(\"Unknown\")\n",
    "\n",
    "# Create yearCollected Column\n",
    "#df = df.assign(yearCollected = '')\n",
    "\n",
    "# Creating event date variable\n",
    "#verbatim_date = df['eventdate']\n",
    "\n",
    "# Establishing vertnet filter\n",
    "#vertnet_date_filter = verbatim_date.str.contains(\"\"\"\"\"\")\n",
    "\n",
    "# Grabbing clean data\n",
    "#verbatim_date_clean= verbatim_date[vertnet_date_filter==False]\n",
    "\n",
    "\n",
    "# Captures year within string\n",
    "def year_search(year):\n",
    "    \"\"\"Search string for 4 digit number and pass to correct function\"\"\"\n",
    "    if (re.search(r'\\d{4}$', year)):\n",
    "        return year_cleaner_front(year)\n",
    "    elif (re.search(r'^\\d{4}', year)):\n",
    "        return year_cleaner_back(year)\n",
    "\n",
    "def year_cleaner_front(year):\n",
    "    \"\"\"Isolate the year at the beginning of the string\"\"\"\n",
    "    cleaned_year = year[len(year)-4:len(year)]\n",
    "    return cleaned_year\n",
    "\n",
    "def year_cleaner_back(year):\n",
    "    \"\"\"Isolate the year at the end of the string\"\"\"\n",
    "    cleaned_year = year[0:4]\n",
    "    return cleaned_year\n",
    "\n",
    "df[\"yearCollected\"] = df[\"eventdate\"].apply(year_search)\n",
    "df[\"yearCollected\"] = df[\"yearCollected\"].fillna(\"Unknown\")\n",
    "\n",
    "df = df.assign(verbatimEventDate = df['verbatimeventdate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning reproductivecondition column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reproductivecondition\"].unique()\n",
    "\n",
    "# TODO: how to handle things like \"T=4.1 x 4.1 mm\"\n",
    "\n",
    "norep_filter = df[\"reproductivecondition\"].str.contains(\"\"\"non-reproductive|not lactating|no lact.\"\"\")\n",
    "preg_filter = df[\"reproductivecondition\"].str.contains(\"\"\"parous|1 emb|1 emb X 1 mm\"\"\")\n",
    "\n",
    "df[\"reproductivecondition\"][norep_filter == True] = \"non-reproductive\"\n",
    "df[\"reproductivecondition\"][preg_filter == True] = \"pregnant\"\n",
    "df[\"reproductivecondition\"][(preg_filter == False) & (norep_filter == False)] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean sex column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up sex column \n",
    "female = df['sex'] == \"female\"\n",
    "male = df['sex'] == \"male\"\n",
    "df['sex'][(female == False) & (male==False)] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding additional required GEOME columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(samplingProtocol = \"Unknown\")\n",
    "df = df.assign(basisOfRecord = \"PreservedSpecimen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearrange columns so that template columns are first, followed by measurement values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column list\n",
    "cols = df.columns.tolist()\n",
    "\n",
    "# Specify desired columns\n",
    "cols = ['catalognumber',\n",
    "        'collectioncode',\n",
    "        'coordinateuncertaintyinmeters',\n",
    "        'dynamicproperties',\n",
    "        'decimallatitude',\n",
    "        'decimallongitude',\n",
    "        'verbatimlongitude',\n",
    "        'verbatimlatitude',\n",
    "        'verbatimelevation',\n",
    "        'institutioncode',\n",
    "        'verbatimEventDate',\n",
    "        'verbatimelevation',\n",
    "        'verbatimlocality',\n",
    "        'maximumelevationinmeters',\n",
    "        'minimumelevationinmeters',\n",
    "        'reproductivecondition',\n",
    "        'locality',\n",
    "        'fieldnotes',\n",
    "        'binomial',\n",
    "        'samplingProtocol',\n",
    "        'occurrenceid',\n",
    "        'occurrenceremarks',\n",
    "        'country',\n",
    "        'sex',\n",
    "        'lifestage_cor',\n",
    "        'basisOfRecord',\n",
    "        'yearCollected',\n",
    "        'body_mass.1.value',\n",
    "        'ear_length.1.value',\n",
    "        'hind_foot_length.1.value',\n",
    "        'tail_length.1.value',\n",
    "        'total_length.1.value',\n",
    "        'body_mass.1.units_inferred',\n",
    "        'ear_length.1.units_inferred',\n",
    "        'hind_foot_length.1.units_inferred',\n",
    "        'tail_length.1.units_inferred',\n",
    "        'total_length.1.units_inferred',\n",
    "        'body_mass.1.estimated_value',\n",
    "        'ear_length.1.estimated_value',\n",
    "        'hind_foot_length.1.estimated_value',\n",
    "        'tail_length.1.estimated_value',\n",
    "        'total_length.1.estimated_value']\n",
    "\n",
    "# Subset dataframe\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching template and column terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns \n",
    "df = df.rename(columns = {'catalognumber':'catalogNumber',\n",
    "                          'collectioncode': 'collectionCode',\n",
    "                          'institutioncode':'institutionCode',\n",
    "                          'coordinateuncertaintyinmeters':'coordinateUncertaintyInMeters',\n",
    "                          'fieldnotes':'eventRemarks',\n",
    "                          'decimallongitude': 'decimalLongitude',\n",
    "                          'decimallatitude':'decimalLatitude',\n",
    "                          'occurrenceid':'occurrenceID',\n",
    "                          'occurrenceremarks':'occurrenceRemarks',\n",
    "                          'verbatimelevation':'verbatimElevation',\n",
    "                          'binomial':'scientificName',\n",
    "                          'reproductivecondition':'reproductiveCondition',\n",
    "                          'maximumelevationinmeters':'maximumElevationInMeters',\n",
    "                          'dynamicproperties':'dynamicProperties',\n",
    "                          'minimumelevationinmeters':'minimumElevationInMeters',\n",
    "                          'verbatimlocality':'verbatimLocality',\n",
    "                          'verbatimlongitude':'verbatimLongitude',\n",
    "                          'verbatimlatitude':'verbatimLatitude',\n",
    "                          'lifestage_cor':'lifeStage'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create materialSampleID which is a UUID for each measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(materialSampleID = '')\n",
    "df['materialSampleID'] = [uuid.uuid4().hex for _ in range(len(df.index))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create eventID and populate it with materialSampleID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(eventID = df[\"materialSampleID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add required GEOME column locality after reassigning locality to verbatimLocality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(locality=\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a unique measurementMethod column for each desired trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of desired traits\n",
    "trait_name_list = [\"body_mass.1\",\"ear_length.1\",\"hind_foot_length.1\",\n",
    "                   \"tail_length.1\",\"total_length.1\"]\n",
    "\n",
    "method_list = [\"measurementMethod_\" + x for x in trait_name_list]\n",
    "df = df.join(pd.DataFrame(index = df.index, columns= method_list))\n",
    "\n",
    "def trait_method(trait):\n",
    "    \"\"\"\n",
    "    Adds measurementMethod information based off of \"True\" values in inferred value\n",
    "    and estimated value columns\n",
    "    \"\"\"\n",
    "    \n",
    "    column = \"measurementMethod_\" + trait\n",
    "    \n",
    "    inferred_column = trait + \".units_inferred\"\n",
    "    estimated_column = trait + \".estimated_value\"\n",
    "    \n",
    "    inferred_filter = df[inferred_column].astype(str).str.contains(\"TRUE|True|true\")\n",
    "    estimated_filter = df[estimated_column].astype(str).str.contains(\"TRUE|True|true\")\n",
    "    \n",
    "    df[column][inferred_filter] = \"Extracted with Traiter ; inferred value\"\n",
    "    df[column][estimated_filter] = \"Extracted with Traiter ; estimated value\"\n",
    "    df[column][estimated_filter & inferred_filter] = \"Extracted with Traiter ; estimated value; inferred value\"\n",
    "    \n",
    "[trait_method(x) for x in trait_name_list]\n",
    "\n",
    "df = df.drop(columns = ['body_mass.1.units_inferred',\n",
    "                        'ear_length.1.units_inferred',\n",
    "                        'hind_foot_length.1.units_inferred',\n",
    "                        'tail_length.1.units_inferred',\n",
    "                        'total_length.1.units_inferred',\n",
    "                        'body_mass.1.estimated_value',\n",
    "                        'ear_length.1.estimated_value',\n",
    "                        'hind_foot_length.1.estimated_value',\n",
    "                        'tail_length.1.estimated_value',\n",
    "                        'total_length.1.estimated_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating long version, first specifiying keep variables, then naming type and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_cols = ['catalogNumber', 'collectionCode', 'decimalLatitude','decimalLongitude',\n",
    "            'verbatimElevation','yearCollected','basisOfRecord','verbatimEventDate',\n",
    "            'institutionCode','lifeStage','verbatimLocality','locality', 'eventRemarks',\n",
    "            'samplingProtocol','country','sex','scientificName','dynamicProperties',\n",
    "            'materialSampleID','eventID','maximumElevationInMeters', 'verbatimLongitude',\n",
    "            'minimumElevationInMeters','coordinateUncertaintyInMeters','verbatimLatitude',\n",
    "            'occurrenceID','occurrenceRemarks','reproductiveCondition']\n",
    "\n",
    "melt_cols = melt_cols + method_list\n",
    "\n",
    "df_long = pd.melt(df,id_vars = melt_cols, var_name = 'measurementType', value_name = 'measurementValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull corresponding column value in measurement_method etc and append it to offical measurementMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_long.assign(measurementMethod = \"\")\n",
    "\n",
    "def method_add(trait,ind):\n",
    "    if trait == \"body_mass.1.value\":\n",
    "        return df_long[\"measurementMethod_body_mass.1\"][ind]\n",
    "    elif trait == \"ear_length.1.value\":\n",
    "        return df_long[\"measurementMethod_ear_length.1\"][ind]\n",
    "    elif trait == \"hind_foot_length.1.value\":\n",
    "        return df_long[\"measurementMethod_hind_foot_length.1\"][ind]\n",
    "    elif trait == \"tail_length.1.value\":\n",
    "        return df_long[\"measurementMethod_tail_length.1\"][ind]\n",
    "    elif trait == \"total_length.1.value\":\n",
    "        return df_long[\"measurementMethod_total_length.1\"][ind]\n",
    "\n",
    "df_long['ind'] = np.arange(len(df_long))\n",
    "\n",
    "df_long['measurementMethod'] = df_long.apply(lambda x: method_add(x.measurementType, x.ind), axis=1)\n",
    "\n",
    "df_long['measurementMethod'] = df_long['measurementMethod'].fillna(\"Extracted with Traiter\")\n",
    "\n",
    "df_long = df_long.drop(columns = method_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching trait and ontology terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trait dictionary \n",
    "trait_dict = {'body_mass.1.value':'body mass',\n",
    "              'ear_length.1.value': 'ear length to notch',\n",
    "              'hind_foot_length.1.value':'pes length',\n",
    "              'tail_length.1.value':'tail length',\n",
    "              'total_length.1.value':'body length'}\n",
    "\n",
    "def trait_rename(trait): \n",
    "    \"\"\"\n",
    "    Renames trait names with trait dictionary\n",
    "    \"\"\"\n",
    "    if trait in trait_dict.keys():\n",
    "        return trait_dict[trait]\n",
    "\n",
    "df_long['measurementType'] = df_long['measurementType'].apply(trait_rename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populating measurementUnit column with appropriate measurement units in long version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create measurementUnit column\n",
    "df_long = df_long.assign(measurementUnit=\"\")\n",
    "\n",
    "#Create filters\n",
    "long_body_mass_filter = df_long['measurementType']==\"body mass\"\n",
    "long_no_body_filter = df_long['measurementType']!=\"body mass\"\n",
    "\n",
    "#Assign units using filters\n",
    "df_long['measurementUnit'][long_body_mass_filter] = \"g\"\n",
    "df_long['measurementUnit'][long_no_body_filter] = \"mm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create diagnosticID which is a unique number for each measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_long.assign(diagnosticID = '')\n",
    "df_long['diagnosticID'] = np.arange(len(df_long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If measurement value equals N/A, delete entire row. Drop range values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop N/A\n",
    "df_long = df_long.dropna(subset=['measurementValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_long' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5ef27d5d4109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_long\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_long' is not defined"
     ]
    }
   ],
   "source": [
    "len(df_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
