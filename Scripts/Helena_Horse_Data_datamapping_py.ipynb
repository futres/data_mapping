{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling Notebook for HMachado Equus Data\n",
    "<br />\n",
    "Neeka Sewnath\n",
    "<br />\n",
    "nsewnath@ufl.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silencing warnings that are unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Horse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing horse data from a comma delimited file\n",
    "data = pd.read_csv(\"../Original_Data/Horse data_Helena.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add individualID and populate with UUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(individualID = '')\n",
    "data['individualID'] = [uuid.uuid4().hex for _ in range(len(data.index))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidy decimalLatitude and decimalLongitude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning decimalLatitude by removing S and making value negative\n",
    "for ind in data.index:\n",
    "    a = data['decimalLatitude'][ind]\n",
    "    b = str(a)\n",
    "    c=b[:-1]\n",
    "    c=\"-\"+c\n",
    "    data['decimalLatitude'][ind] = c\n",
    "\n",
    "# Cleaning decimalLongitude by removing W and making value negative\n",
    "for ind in data.index:\n",
    "    a = data['decimalLongitude'][ind]\n",
    "    b = str(a)\n",
    "    c=b[:-1]\n",
    "    c=\"-\"+c\n",
    "    data['decimalLongitude'][ind] = c\n",
    "\n",
    "na_long = data['decimalLatitude']==\"-na\"\n",
    "na_lat = data['decimalLongitude']==\"-na\"\n",
    "data['decimalLatitude'][(na_long == True)]= \"\"\n",
    "data['decimalLongitude'][(na_lat == True)]= \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining SpecimenType to MeasurementType Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['test'] = data['specimenType'].str.cat(data['measurementType'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing basisOfRecord and measurementUnit columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization from fossil to FossilSpecimen\n",
    "data.loc[data['basisOfRecord'] == 'fossil', 'basisOfRecord'] = 'FossilSpecimen'\n",
    "#horseData['basisOfRecord']\n",
    "\n",
    "# Measurement unit from millimeters to mm\n",
    "data.loc[data['measurementUnit'] == 'millimeters', 'measurementUnit'] = 'mm'\n",
    "#horseData['measurementUnit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearrange columns so that template columns are first, followed by measurement values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column list\n",
    "cols = data.columns.tolist()\n",
    "\n",
    "# Specify desired columns\n",
    "cols = ['institutionCode',\n",
    "        'individualID',\n",
    "        'collectionCode',\n",
    "        'specimenID',\n",
    "        'side',\n",
    "        'test',\n",
    "        'scientificName',\n",
    "        'decimalLatitude',\n",
    "        'decimalLongitude',\n",
    "        'sitename',\n",
    "        'verbatimLocality',\n",
    "        'basisOfRecord',\n",
    "        'measurementValue',\n",
    "        'measurementUnit',\n",
    "        'lithostratigraphicTerms',\n",
    "        'formation',\n",
    "        'member',\n",
    "        'references']\n",
    "\n",
    "#Subset dataframe\n",
    "data = data[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching template and column terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming columns \n",
    "data = data.rename(columns = {'specimenID':'catalogNumber',\n",
    "                              'specimenType':'skeletalElement',\n",
    "                              'side':'measurementSide',\n",
    "                              'sitename':'locality',\n",
    "                              'test': 'measurementType',\n",
    "                              'reference':'measurementMethod'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace names of terms avaliable in GEOME and subset data by avaliable terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace names of terms avaliable in GEOME\n",
    "\n",
    "# Read mapping file \n",
    "mapping_file = pd.read_csv(\"../Mapping Files/ontology_codeBook.csv\")\n",
    "\n",
    "# Create subset of those within FOVT or OBA\n",
    "map_subset = mapping_file[(mapping_file[\"Status\"]==\"in FOVT\") | (mapping_file[\"Status\"]== \"in OBA\") ]\n",
    "\n",
    "# Create a subset of Helena data\n",
    "helena_subset = map_subset[map_subset[\"name\"] == \"Helena\"]\n",
    "\n",
    "# Create dictionary of terms\n",
    "map_dict = pd.Series(helena_subset.term.values,index=helena_subset.label).to_dict()\n",
    "\n",
    "# Map the new terms onto the old terms in the dataframe \n",
    "data[\"measurementType\"] = (pd.Series(data[\"measurementType\"])).map(map_dict)\n",
    "\n",
    "data = data.dropna(subset=['measurementType'])\n",
    "data = data.dropna(subset=['measurementValue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create materialSampleID which is a UUID for each measurement. Populate eventID with materialSampleID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.assign(materialSampleID = '')\n",
    "data['materialSampleID'] = [uuid.uuid4().hex for _ in range(len(data.index))]\n",
    "\n",
    "data = data.assign(eventID = data[\"materialSampleID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create GEOME required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"scientificName\"] = data[\"scientificName\"].fillna(\"Unknown\")\n",
    "data = data.assign(measurementMethod = \"unknown\")\n",
    "data = data.assign(country = \"unknown\")\n",
    "data = data.assign(yearCollected = \"unknown\")\n",
    "data = data.assign(samplingProtocol = \"unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create diagnosticID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create diagnosticID which is a UUID for each measurement\n",
    "data = data.assign(diagnosticID = '')\n",
    "data['diagnosticID'] = [uuid.uuid4() for _ in range(len(data.index))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write file to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing the final dataframe as csv file\n",
    "data.to_csv('../Mapped_Data/FuTRES_Equus_HMachado_Americas_paleo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
